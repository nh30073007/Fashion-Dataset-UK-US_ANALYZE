{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402c86a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name                    0\n",
      "Price                           0\n",
      "Brand                           0\n",
      "Category                        0\n",
      "Description                     0\n",
      "Rating                          0\n",
      "Review Count                    0\n",
      "Style Attributes                0\n",
      "Total Sizes                     0\n",
      "Available Sizes                 0\n",
      "Color                           0\n",
      "Purchase History                0\n",
      "Age                             0\n",
      "Fashion Magazines               0\n",
      "Fashion Influencers             0\n",
      "Season                          0\n",
      "Time Period Highest Purchase    0\n",
      "Customer Reviews                0\n",
      "Social Media Comments           0\n",
      "feedback                        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nh013\\AppData\\Local\\Temp\\ipykernel_2412\\3656075257.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_numerical['Age'] = df_numerical['Age'].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Brand_Alexander McQueen  Brand_Burberry  Brand_Calvin Klein  \\\n",
      "0                             0               0                   0   \n",
      "1                             0               0                   0   \n",
      "2                             0               0                   0   \n",
      "3                             1               0                   0   \n",
      "4                             0               0                   0   \n",
      "...                         ...             ...                 ...   \n",
      "999995                        0               0                   0   \n",
      "999996                        0               0                   0   \n",
      "999997                        0               0                   0   \n",
      "999998                        0               0                   0   \n",
      "999999                        0               1                   0   \n",
      "\n",
      "        Brand_Jigsaw  Brand_Mulberry  Brand_Ralph Lauren  Brand_Ted Baker  \\\n",
      "0                  0               0                   1                0   \n",
      "1                  0               0                   0                1   \n",
      "2                  1               0                   0                0   \n",
      "3                  0               0                   0                0   \n",
      "4                  0               0                   0                0   \n",
      "...              ...             ...                 ...              ...   \n",
      "999995             0               1                   0                0   \n",
      "999996             0               1                   0                0   \n",
      "999997             0               1                   0                0   \n",
      "999998             0               0                   1                0   \n",
      "999999             0               0                   0                0   \n",
      "\n",
      "        Brand_Tommy Hilfiger  Category_Accessories  Category_Activewear  ...  \\\n",
      "0                          0                     0                    0  ...   \n",
      "1                          0                     0                    0  ...   \n",
      "2                          0                     0                    0  ...   \n",
      "3                          0                     0                    0  ...   \n",
      "4                          1                     0                    0  ...   \n",
      "...                      ...                   ...                  ...  ...   \n",
      "999995                     0                     1                    0  ...   \n",
      "999996                     0                     0                    1  ...   \n",
      "999997                     0                     0                    0  ...   \n",
      "999998                     0                     0                    0  ...   \n",
      "999999                     0                     0                    0  ...   \n",
      "\n",
      "        Season_Spring/Summer  Season_Summer  Season_Winter  \\\n",
      "0                          0              0              0   \n",
      "1                          0              0              1   \n",
      "2                          0              1              0   \n",
      "3                          0              0              0   \n",
      "4                          0              0              0   \n",
      "...                      ...            ...            ...   \n",
      "999995                     0              0              1   \n",
      "999996                     0              0              0   \n",
      "999997                     0              1              0   \n",
      "999998                     1              0              0   \n",
      "999999                     1              0              0   \n",
      "\n",
      "        Time Period Highest Purchase_Daytime  \\\n",
      "0                                          1   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          1   \n",
      "...                                      ...   \n",
      "999995                                     0   \n",
      "999996                                     0   \n",
      "999997                                     0   \n",
      "999998                                     0   \n",
      "999999                                     0   \n",
      "\n",
      "        Time Period Highest Purchase_Evening  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "999995                                     0   \n",
      "999996                                     1   \n",
      "999997                                     1   \n",
      "999998                                     1   \n",
      "999999                                     1   \n",
      "\n",
      "        Time Period Highest Purchase_Holiday  \\\n",
      "0                                          0   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "999995                                     1   \n",
      "999996                                     0   \n",
      "999997                                     0   \n",
      "999998                                     0   \n",
      "999999                                     0   \n",
      "\n",
      "        Time Period Highest Purchase_Nighttime  \\\n",
      "0                                            0   \n",
      "1                                            0   \n",
      "2                                            1   \n",
      "3                                            0   \n",
      "4                                            0   \n",
      "...                                        ...   \n",
      "999995                                       0   \n",
      "999996                                       0   \n",
      "999997                                       0   \n",
      "999998                                       0   \n",
      "999999                                       0   \n",
      "\n",
      "        Time Period Highest Purchase_Weekend   Age    Rating  \n",
      "0                                          0  24.0  1.421706  \n",
      "1                                          1  61.0  1.037677  \n",
      "2                                          0  27.0  3.967106  \n",
      "3                                          1  50.0  2.844659  \n",
      "4                                          0  23.0  1.183242  \n",
      "...                                      ...   ...       ...  \n",
      "999995                                     0  37.0  3.534252  \n",
      "999996                                     0  52.0  1.896160  \n",
      "999997                                     0  25.0  3.168064  \n",
      "999998                                     0  29.0  4.764673  \n",
      "999999                                     0  35.0  1.232505  \n",
      "\n",
      "[1000000 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "#PREPROCESS STEP\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "# USING FUNCTION TO HANDLE_OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5*IQR\n",
    "    upper_bound = Q3 + 1.5*IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "# DATASET\n",
    "df = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\FASION DATASET UK AND US\\mock_fashion_data_uk_us.csv\")\n",
    "\n",
    "#FEATURE \n",
    "\n",
    "df=df[['Product Name','Price','Brand','Category','Description','Rating','Review Count','Style Attributes','Total Sizes','Available Sizes','Color','Purchase History','Age','Fashion Magazines','Fashion Influencers','Season','Time Period Highest Purchase','Customer Reviews','Social Media Comments','feedback'\n",
    "      ]]\n",
    "\n",
    "# IDENTIFYING MISSINFG VALUES\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# HANDLE MISSING VALUES\n",
    "df.fillna(value=np.nan, inplace=True)\n",
    "\n",
    "# DROP MISSING ROWS\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# REMOVE DUPLICATES\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# SELECT CATEGORICAL COLUMN \n",
    "categorical_cols = ['Brand', 'Category', 'Style Attributes', 'Total Sizes', 'Available Sizes', 'Color', 'Purchase History',\n",
    "                    'Fashion Magazines', 'Fashion Influencers', 'Season', 'Time Period Highest Purchase']\n",
    "\n",
    "df_categorical = df[categorical_cols]\n",
    "\n",
    "# CATEGORICAL COLUMN TO NUMERIC USING ONE HOT ENCODING\n",
    "df_encoded = pd.get_dummies(df_categorical)\n",
    "\n",
    "# EXTRACT NUMERIC COLUMN \n",
    "numerical_cols = ['Age', 'Rating']\n",
    "\n",
    "df_numerical = df[numerical_cols]\n",
    "\n",
    "# CONVERT STRING VALUES TO FLOAT\n",
    "df_numerical['Age'] = df_numerical['Age'].astype(float)\n",
    "\n",
    "# COMBINE THE  CATEGORICAL FEATURE AND NUMERICAL FEATURE \n",
    "df_preprocessed = pd.concat([df_encoded, df_numerical], axis=1)\n",
    "\n",
    "# NORMALIZE AND SCALING ALL NUMERICAL COLUMN\n",
    "scaler = MinMaxScaler()\n",
    "numerical_cols = df.select_dtypes(include='number').columns\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = df.select_dtypes(include='number').columns\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "\n",
    "print(df_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e5ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc5ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nh013\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Product Name      Price         Brand   Category Description    Rating  \\\n",
      "0            r9x4  42.813271  calvin klein  accessori   Very Good  2.663849   \n",
      "1            s8f1  30.256069      mulberri    jewelri    Very Bad  2.325738   \n",
      "2            o2a6  54.230751  tommi hilfig     bottom   Very Good  1.440138   \n",
      "3            g0v3  34.380568  ralph lauren    jewelri    Not Good  3.317355   \n",
      "4            r9x4  63.095972  ralph lauren      dress    Not Good  3.381028   \n",
      "...           ...        ...           ...        ...         ...       ...   \n",
      "1479         a7i6  35.569663     ted baker   swimwear       Worst  3.125005   \n",
      "1480         n0y3  46.426757  tommi hilfig        top        Good  3.504431   \n",
      "1481         r3k6  74.321983        jigsaw   swimwear    Not Good  1.576507   \n",
      "1482         i9h8  67.336867     ted baker    jewelri   Very Good  3.668600   \n",
      "1483         c1s9  43.173677     ted baker     bottom         Bad  3.396107   \n",
      "\n",
      "      Review Count Style Attributes Total Sizes Available Sizes  Color  \\\n",
      "0              197       Minimalist    S, L, XL               S    Red   \n",
      "1              207           Preppy     S, M, L               M  Green   \n",
      "2                3           Sporty    S, L, XL              XL    Red   \n",
      "3              379           Sporty     S, M, L              XL   Blue   \n",
      "4               75       Minimalist    S, L, XL               M   Blue   \n",
      "...            ...              ...         ...             ...    ...   \n",
      "1479           184        Glamorous     S, M, L               L   Blue   \n",
      "1480           353         Bohemian    S, L, XL               M  Green   \n",
      "1481            78             Edgy    S, L, XL               L  Black   \n",
      "1482           114        Glamorous    S, L, XL              XL  Black   \n",
      "1483           195           Casual    M, L, XL               S  Green   \n",
      "\n",
      "     Purchase History  Age Fashion Magazines Fashion Influencers  \\\n",
      "0            Very Low   20           InStyle      Leandra Medine   \n",
      "1       Below Average   34            Grazia      Olivia Palermo   \n",
      "2         Significant   27       Fashionista     Chiara Ferragni   \n",
      "3            Very Low   20           InStyle      Leandra Medine   \n",
      "4                 Low   58              Elle       Camila Coelho   \n",
      "...               ...  ...               ...                 ...   \n",
      "1479              Low   55                 W      Olivia Palermo   \n",
      "1480          Average   18              Elle      Leandra Medine   \n",
      "1481         Very Low   34                 W      Olivia Palermo   \n",
      "1482         Very Low   38           Glamour     Chiara Ferragni   \n",
      "1483              Low   43              Elle       Song of Style   \n",
      "\n",
      "             Season Time Period Highest Purchase Customer Reviews  \\\n",
      "0            Summer                      Daytime          unknown   \n",
      "1     Spring/Summer                      Holiday              neg   \n",
      "2              Fall                      Evening          unknown   \n",
      "3       Fall/Winter                      Holiday              neg   \n",
      "4            Summer                      Evening          unknown   \n",
      "...             ...                          ...              ...   \n",
      "1479         Summer                      Holiday          neutral   \n",
      "1480         Spring                      Holiday              neg   \n",
      "1481           Fall                    Nighttime              neg   \n",
      "1482         Summer                      Daytime              mix   \n",
      "1483         Summer                      Holiday              neg   \n",
      "\n",
      "     Social Media Comments feedback  \n",
      "0                    posit           \n",
      "1                  neutral           \n",
      "2                  neutral      neg  \n",
      "3                      neg  unknown  \n",
      "4                      neg           \n",
      "...                    ...      ...  \n",
      "1479               unknown    posit  \n",
      "1480               unknown    posit  \n",
      "1481                 posit    posit  \n",
      "1482                        unknown  \n",
      "1483                   neg           \n",
      "\n",
      "[1484 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "# preprocess step using NLTK FOR text data....\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# DATASET\n",
    "df = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\FASION DATASET UK AND US\\mock_fashion_data_uk_us.csv\")\n",
    "\n",
    "# REMOVE MISSING VALUES \n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# REMOVE DUPLICATE ROWS\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# REMOVE ANY URLS\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['feedback'] = df['feedback'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['Brand'] = df['Brand'].apply(lambda x: re.sub(r'http\\S+', '', str(x)))\n",
    "df['Category'] = df['Category'].apply(lambda x: re.sub(r'http\\S+', '', str(x)))\n",
    "\n",
    "# REMOVE SPECIAL CHARACTERS\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['feedback'] = df['feedback'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['Brand'] = df['Brand'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
    "df['Category'] = df['Category'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
    "\n",
    "# CONVERT ALL TEXT TO LOWERCASE\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: x.lower())\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: x.lower())\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: x.lower())\n",
    "df['feedback'] = df['feedback'].apply(lambda x: x.lower())\n",
    "df['Brand'] = df['Brand'].str.lower()\n",
    "df['Category'] = df['Category'].str.lower()\n",
    "\n",
    "# REMOVE STOP WORDS\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['feedback'] = df['feedback'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['Brand'] = df['Brand'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))\n",
    "df['Category'] = df['Category'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))\n",
    "\n",
    "\n",
    "# STEMMING\n",
    "stemmer = PorterStemmer()\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df['feedback'] = df['feedback'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df['Brand'] = df['Brand'].apply(lambda x: ' '.join([stemmer.stem(word) for word in str(x).split()]))\n",
    "df['Category'] = df['Category'].apply(lambda x: ' '.join([stemmer.stem(word) for word in str(x).split()]))\n",
    "\n",
    "\n",
    "# USING GROUPBY METHOD FOR TOP PRODUCTS\n",
    "top_products = df.groupby('Product Name').size().nlargest(50).index.tolist()\n",
    "\n",
    "# CREATE DATAFRAME ONLY FOR THE TOP PRODUCTS\n",
    "df_top_products = df[df['Product Name'].isin(top_products)]\n",
    "\n",
    "# SHUFFLE THE ROWS OF THE DATAFRAME\n",
    "df_top_products = df_top_products.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(df_top_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478321d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eedc971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nh013\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name                    0\n",
      "Price                           0\n",
      "Brand                           0\n",
      "Category                        0\n",
      "Description                     0\n",
      "Rating                          0\n",
      "Review Count                    0\n",
      "Style Attributes                0\n",
      "Total Sizes                     0\n",
      "Available Sizes                 0\n",
      "Color                           0\n",
      "Purchase History                0\n",
      "Age                             0\n",
      "Fashion Magazines               0\n",
      "Fashion Influencers             0\n",
      "Season                          0\n",
      "Time Period Highest Purchase    0\n",
      "Customer Reviews                0\n",
      "Social Media Comments           0\n",
      "feedback                        0\n",
      "dtype: int64\n",
      "      Brand_alexand mcqueen  Brand_burberri  Brand_calvin klein  Brand_jigsaw  \\\n",
      "0                         0               0                   0             0   \n",
      "1                         0               0                   1             0   \n",
      "2                         0               1                   0             0   \n",
      "3                         0               0                   0             0   \n",
      "4                         0               0                   0             0   \n",
      "...                     ...             ...                 ...           ...   \n",
      "1479                      0               1                   0             0   \n",
      "1480                      0               1                   0             0   \n",
      "1481                      0               1                   0             0   \n",
      "1482                      0               0                   0             0   \n",
      "1483                      0               0                   0             0   \n",
      "\n",
      "      Brand_mulberri  Brand_ralph lauren  Brand_ted baker  Brand_tommi hilfig  \\\n",
      "0                  0                   1                0                   0   \n",
      "1                  0                   0                0                   0   \n",
      "2                  0                   0                0                   0   \n",
      "3                  1                   0                0                   0   \n",
      "4                  0                   1                0                   0   \n",
      "...              ...                 ...              ...                 ...   \n",
      "1479               0                   0                0                   0   \n",
      "1480               0                   0                0                   0   \n",
      "1481               0                   0                0                   0   \n",
      "1482               0                   1                0                   0   \n",
      "1483               0                   0                0                   1   \n",
      "\n",
      "      Category_accessori  Category_activewear  ...  Season_Winter  \\\n",
      "0                      0                    1  ...              0   \n",
      "1                      0                    0  ...              0   \n",
      "2                      0                    0  ...              0   \n",
      "3                      0                    0  ...              1   \n",
      "4                      0                    0  ...              0   \n",
      "...                  ...                  ...  ...            ...   \n",
      "1479                   0                    0  ...              0   \n",
      "1480                   0                    0  ...              1   \n",
      "1481                   0                    0  ...              0   \n",
      "1482                   0                    0  ...              0   \n",
      "1483                   0                    0  ...              0   \n",
      "\n",
      "      Time Period Highest Purchase_Daytime  \\\n",
      "0                                        0   \n",
      "1                                        0   \n",
      "2                                        0   \n",
      "3                                        1   \n",
      "4                                        0   \n",
      "...                                    ...   \n",
      "1479                                     0   \n",
      "1480                                     0   \n",
      "1481                                     0   \n",
      "1482                                     0   \n",
      "1483                                     0   \n",
      "\n",
      "      Time Period Highest Purchase_Evening  \\\n",
      "0                                        0   \n",
      "1                                        1   \n",
      "2                                        0   \n",
      "3                                        0   \n",
      "4                                        0   \n",
      "...                                    ...   \n",
      "1479                                     0   \n",
      "1480                                     0   \n",
      "1481                                     0   \n",
      "1482                                     1   \n",
      "1483                                     0   \n",
      "\n",
      "      Time Period Highest Purchase_Holiday  \\\n",
      "0                                        0   \n",
      "1                                        0   \n",
      "2                                        1   \n",
      "3                                        0   \n",
      "4                                        1   \n",
      "...                                    ...   \n",
      "1479                                     1   \n",
      "1480                                     0   \n",
      "1481                                     0   \n",
      "1482                                     0   \n",
      "1483                                     0   \n",
      "\n",
      "      Time Period Highest Purchase_Nighttime  \\\n",
      "0                                          1   \n",
      "1                                          0   \n",
      "2                                          0   \n",
      "3                                          0   \n",
      "4                                          0   \n",
      "...                                      ...   \n",
      "1479                                       0   \n",
      "1480                                       1   \n",
      "1481                                       0   \n",
      "1482                                       0   \n",
      "1483                                       0   \n",
      "\n",
      "      Time Period Highest Purchase_Weekend     Price    Rating  Review Count  \\\n",
      "0                                        0 -1.033940 -0.253184     -0.687699   \n",
      "1                                        0  1.524568 -1.155052      0.909130   \n",
      "2                                        0  0.101371  0.686541     -1.437934   \n",
      "3                                        0 -1.710596  1.517067      1.377166   \n",
      "4                                        0 -0.804279  0.306581      0.902247   \n",
      "...                                    ...       ...       ...           ...   \n",
      "1479                                     0  0.820864  1.348777      1.549238   \n",
      "1480                                     0 -0.049443  0.001212     -1.327808   \n",
      "1481                                     1 -1.045141 -1.317796     -0.199015   \n",
      "1482                                     0  1.217898  0.504392     -0.639519   \n",
      "1483                                     1  0.823490  0.108278      1.026139   \n",
      "\n",
      "           Age  \n",
      "0    -0.001958  \n",
      "1     0.370536  \n",
      "2     1.711514  \n",
      "3     1.488018  \n",
      "4    -1.566433  \n",
      "...        ...  \n",
      "1479  1.264522  \n",
      "1480 -1.119440  \n",
      "1481  1.041025  \n",
      "1482 -0.970442  \n",
      "1483  1.413519  \n",
      "\n",
      "[1484 rows x 84 columns]\n",
      "     Product Name      Price         Brand    Category Description    Rating  \\\n",
      "0            r3k6  28.383780  ralph lauren  activewear    Not Good  2.673898   \n",
      "1            a7i6  95.190257  calvin klein      bottom    Very Bad  1.637190   \n",
      "2            u4o2  58.028439      burberri      bottom        Best  3.754123   \n",
      "3            t2k6  10.715266      mulberri      bottom    Very Bad  4.708823   \n",
      "4            g0v3  34.380568  ralph lauren     jewelri    Not Good  3.317355   \n",
      "...           ...        ...           ...         ...         ...       ...   \n",
      "1479         m9b8  76.815493      burberri      bottom   Very Good  4.515372   \n",
      "1480         j1a4  54.090474      burberri         top    Not Good  2.966329   \n",
      "1481         n4b8  28.091284      burberri     lingeri   Very Good  1.450114   \n",
      "1482         l0g5  87.182632  ralph lauren      bottom    Not Good  3.544741   \n",
      "1483         o2a6  76.884051  tommi hilfig   outerwear   Very Good  3.089404   \n",
      "\n",
      "      Review Count Style Attributes Total Sizes Available Sizes  Color  \\\n",
      "0              148        Glamorous    M, L, XL               M    Red   \n",
      "1              380       Minimalist    S, L, XL              XL    Red   \n",
      "2               39        Glamorous    M, L, XL               M  Black   \n",
      "3              448           Sporty     S, M, L               L    Red   \n",
      "4              379           Sporty     S, M, L              XL   Blue   \n",
      "...            ...              ...         ...             ...    ...   \n",
      "1479           473        Glamorous     S, M, L               M  Black   \n",
      "1480            55           Casual    S, L, XL              XL  Green   \n",
      "1481           219           Preppy    M, L, XL              XL    Red   \n",
      "1482           155        Glamorous    M, L, XL               S  Black   \n",
      "1483           397          Vintage     S, M, L               L    Red   \n",
      "\n",
      "     Purchase History  Age Fashion Magazines Fashion Influencers  \\\n",
      "0         Significant   41           InStyle      Leandra Medine   \n",
      "1          Negligible   46           InStyle       Camila Coelho   \n",
      "2                High   64            Grazia       Camila Coelho   \n",
      "3       Above Average   61           Glamour      Olivia Palermo   \n",
      "4            Very Low   20           InStyle      Leandra Medine   \n",
      "...               ...  ...               ...                 ...   \n",
      "1479              Low   58      Marie Claire          Aimee Song   \n",
      "1480             High   26           InStyle      Julie Sariñana   \n",
      "1481           Medium   55      Marie Claire      Julie Sariñana   \n",
      "1482             High   28           Glamour          Gigi Hadid   \n",
      "1483    Below Average   60             Vogue     Negin Mirsalehi   \n",
      "\n",
      "             Season Time Period Highest Purchase Customer Reviews  \\\n",
      "0            Summer                    Nighttime              neg   \n",
      "1     Spring/Summer                      Evening              neg   \n",
      "2              Fall                      Holiday              neg   \n",
      "3            Winter                      Daytime              neg   \n",
      "4       Fall/Winter                      Holiday              neg   \n",
      "...             ...                          ...              ...   \n",
      "1479           Fall                      Holiday              mix   \n",
      "1480         Winter                    Nighttime            posit   \n",
      "1481         Summer                      Weekend          neutral   \n",
      "1482  Spring/Summer                      Evening          unknown   \n",
      "1483           Fall                      Weekend          unknown   \n",
      "\n",
      "     Social Media Comments feedback  \n",
      "0                      neg    posit  \n",
      "1                  unknown           \n",
      "2                      mix           \n",
      "3                                    \n",
      "4                      neg  unknown  \n",
      "...                    ...      ...  \n",
      "1479                 posit      mix  \n",
      "1480               unknown  neutral  \n",
      "1481               neutral      neg  \n",
      "1482                   neg      mix  \n",
      "1483                   mix    posit  \n",
      "\n",
      "[1484 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nh013\\AppData\\Local\\Temp\\ipykernel_10296\\858363391.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_numerical['Price'] = df_numerical['Price'].astype(float)\n",
      "C:\\Users\\nh013\\AppData\\Local\\Temp\\ipykernel_10296\\858363391.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_numerical['Rating'] = df_numerical['Rating'].astype(float)\n",
      "C:\\Users\\nh013\\AppData\\Local\\Temp\\ipykernel_10296\\858363391.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_numerical['Review Count'] = df_numerical['Review Count'].astype(float)\n",
      "C:\\Users\\nh013\\AppData\\Local\\Temp\\ipykernel_10296\\858363391.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_numerical['Age'] = df_numerical['Age'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "#combines the preprocessing steps and feature selection using the top products, and then performs normalization and scaling \n",
    "#on the numerical features\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# FUNCTION TO HANDLE OUTLIER\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "# DATASET \n",
    "df = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\FASION DATASET UK AND US\\mock_fashion_data_uk_us.csv\")\n",
    "\n",
    "# REMOVE MISSING VALUES\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# REMOVE DUPLICATES\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# REMOVE ANY URLS\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['feedback'] = df['feedback'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "df['Brand'] = df['Brand'].apply(lambda x: re.sub(r'http\\S+', '', str(x)))\n",
    "df['Category'] = df['Category'].apply(lambda x: re.sub(r'http\\S+', '', str(x)))\n",
    "\n",
    "#REMOVE ANY SPECIAL CHERECHTER\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['feedback'] = df['feedback'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['Brand'] = df['Brand'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
    "df['Category'] = df['Category'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
    "\n",
    "\n",
    "# CONVERT ALL TEXT TO LOWER CASE\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: x.lower())\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: x.lower())\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: x.lower())\n",
    "df['feedback'] = df['feedback'].apply(lambda x: x.lower())\n",
    "df['Brand'] = df['Brand'].str.lower()\n",
    "df['Category'] = df['Category'].str.lower()\n",
    "\n",
    "\n",
    "# REMOVE STOP WORDS\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['feedback'] = df['feedback'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['Brand'] = df['Brand'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))\n",
    "df['Category'] = df['Category'].apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))\n",
    "\n",
    "\n",
    "# STEMMING\n",
    "stemmer = PorterStemmer()\n",
    "df['Customer Reviews'] = df['Customer Reviews'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df['Product Name'] = df['Product Name'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df['Social Media Comments'] = df['Social Media Comments'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df['feedback'] = df['feedback'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "df['Brand'] = df['Brand'].apply(lambda x: ' '.join([stemmer.stem(word) for word in str(x).split()]))\n",
    "df['Category'] = df['Category'].apply(lambda x: ' '.join([stemmer.stem(word) for word in str(x).split()]))\n",
    "\n",
    "\n",
    "# GROUPBY METHOD FOR TOP PRODUCTS\n",
    "top_products = df.groupby('Product Name').size().nlargest(50).index.tolist()\n",
    "\n",
    "# DATAFRAME ONLY FOR TOP PRODUCTS\n",
    "df_top_products = df[df['Product Name'].isin(top_products)]\n",
    "\n",
    "# SUFFLE THE ROWS OF THE DATAFRAME\n",
    "df_top_products = df_top_products.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# FEATURE SELECTION\n",
    "df_top_products = df_top_products[['Product Name', 'Price', 'Brand', 'Category', 'Description', 'Rating', 'Review Count',\n",
    "                                   'Style Attributes', 'Total Sizes', 'Available Sizes', 'Color', 'Purchase History',\n",
    "                                   'Age', 'Fashion Magazines', 'Fashion Influencers', 'Season',\n",
    "                                   'Time Period Highest Purchase', 'Customer Reviews', 'Social Media Comments', 'feedback']]\n",
    "\n",
    "# IDENTIFYING MISSING VALUES\n",
    "print(df_top_products.isnull().sum())\n",
    "\n",
    "# HANDLE MISSING VALUES\n",
    "df_top_products.fillna(value=np.nan, inplace=True)\n",
    "\n",
    "# DROP MISSING ROWS\n",
    "df_top_products.dropna(inplace=True)\n",
    "\n",
    "# REMOVE DUPLICATES\n",
    "df_top_products.drop_duplicates(inplace=True)\n",
    "\n",
    "# SELECT CATEGORICAL COLUMN\n",
    "categorical_cols = ['Brand', 'Category', 'Style Attributes', 'Total Sizes', 'Available Sizes', 'Color',\n",
    "                    'Purchase History', 'Fashion Magazines', 'Fashion Influencers', 'Season',\n",
    "                    'Time Period Highest Purchase']\n",
    "\n",
    "df_categorical = df_top_products[categorical_cols]\n",
    "\n",
    "# ONE HOT ENCODING\n",
    "df_encoded = pd.get_dummies(df_categorical)\n",
    "\n",
    "#NUMERICAL COLUMN\n",
    "numerical_cols = ['Price', 'Rating', 'Review Count', 'Age']\n",
    "\n",
    "df_numerical = df_top_products[numerical_cols]\n",
    "\n",
    "# CONVERT STRING VALUES TO FLOAT\n",
    "df_numerical['Price'] = df_numerical['Price'].astype(float)\n",
    "df_numerical['Rating'] = df_numerical['Rating'].astype(float)\n",
    "df_numerical['Review Count'] = df_numerical['Review Count'].astype(float)\n",
    "df_numerical['Age'] = df_numerical['Age'].astype(float)\n",
    "\n",
    "# COMBINE THE CATEGORICAL FEATURE AND NUMERICAL FEATURE\n",
    "df_preprocessed = pd.concat([df_encoded, df_numerical], axis=1)\n",
    "\n",
    "# NORMALIZE AND SCALE AND STANDARIZE ALL NUMERICAL COLUMN\n",
    "scaler = MinMaxScaler()\n",
    "numerical_cols = df_numerical.columns\n",
    "df_preprocessed[numerical_cols] = scaler.fit_transform(df_numerical)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_preprocessed[numerical_cols] = scaler.fit_transform(df_preprocessed[numerical_cols])\n",
    "\n",
    "print(df_preprocessed)\n",
    "print(df_top_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7cd09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
